#!/bin/bash

cat <<EOF > help.txt
# Your Quest
-------------------------------

By modifying python/challenge.py, node/challenge.js, go/challenge.go, or using gsutil directly, upload
the local file foo.txt to a file named bar.txt in the bucket you created in the
last challenge.

Hit the "Check" button when you are done.

Coding Your Solution
-------------------------------

If you run 'ls', you will see folders for each supported language; currently
python, node (JavaScript), and go.

Once you're ready to write some code, use vim, nano, or emacs to edit the
challenge file in one of these directories, then use the given interpreter
to execute it.

# Using gsutil
-------------------------------

You will also find the gsutil utility installed, and the environment variable
\$BUCKET_NAME set. Run "gsutil --help" for information about this command.
EOF

cat <<EOF > hint.txt
Hint:
----

try running: 

gsutil cp /root/foo.txt gs://.../bar.txt.

replacing "..." with the local filename.
EOF

cat <<EOF > node/challenge.js
// Imports the Google Cloud client library
const {Storage} = require('@google-cloud/storage')

// Globally unique bucket name (don't change this).
const bucketName = "bucket-$(cat /usr/local/lib/UUID)"

// An authenticated storage API client.
const storage = new Storage()

async function uploadFile () {
  // implement logic for uploading /root/foo.txt to bar.txt
  // using the method "bucket" on the Storage class,
  // and the method "upload" on the bucket class returned.
  //
  // upload accepts the first argument localFilePath, and a
  // second argument options; set the key "destination" on
  // options, to set the remote filename.
}

uploadFile()
EOF

cat <<EOF > /root/foo.txt
hello world!
EOF

cat <<EOF > /usr/local/lib/google-cloud-sdk/bin/check-for-file.js
const {Storage} = require('@google-cloud/storage')
const storage = new Storage()
const name = process.argv[2]
const bucketName = process.env.BUCKET_NAME
async function checkForFile () {
    try {
      const [files] = await storage.bucket(bucketName).getFiles()
      let foundFile = false
      files.forEach(file => {
          if (file.name === name) foundFile = true
      });
      if (!foundFile) {
          console.error('could not find file ' + name)
          process.exit(1)
      }
    } catch (err) {
      console.error(err)
      process.exit(1)
    }
}
checkForFile()
EOF

mkdir root/python

cat <<EOF > python/challenge.py
import os
from google.cloud import storage

# the bucket was already created
# filename =  the source  file name
# desitnation_name = the name to give the uploaded object
def upload_blob():
    storage_client = storage.Client()
    bucket_name = os.environ['BUCKET_NAME']
    bucket = storage_client.get_bucket(bucket_name)
    # using the method "blob" on bucket, which accepts the
    # option remote_file_name.
    # and using the method upload_from_file on "blob",
    # which accepts the source_file_name, upload /root/foo.txt to bar.txt.

if __name__ == '__main__':
    upload_blob()
EOF

# go code samples and stubbed out challenge.
cat <<EOF > go/challenge.go
package main

import (
	"cloud.google.com/go/storage"
	"context"
	"io"
	"log"
	"os"
)

func main() {
	ctx := context.Background()

	// [START setup]
	client, err := storage.NewClient(ctx)
	if err != nil {
		log.Fatal(err)
	}
	// [END setup]

	// Give the bucket a unique name.
	bucketName := os.Getenv("BUCKET_NAME")
	if err := write(client, bucketName, "bar.txt"); err != nil {
		log.Fatalf("Cannot write object: %v", err)
	}
}

func write(client *storage.Client, bucketName, object string) error {
  // Using the code below, upload /root/foo.txt to the remote bar.txt.
  ctx := context.Background()
  // f, err := os.Open("/root/foo.txt")
  // if err != nil {
  // return err
  // }
  // defer f.Close()

  // wc := client.Bucket(bucketName).Object(object).NewWriter(ctx)
  // if _, err = io.Copy(wc, f); err != nil {
  // return err
  // }
  // if err := wc.Close(); err != nil {
  //  return err
  // }
  return nil
}
EOF
